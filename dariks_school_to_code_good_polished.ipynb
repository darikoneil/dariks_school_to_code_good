{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Darik's School to Code Good](https://raw.githubusercontent.com/darikoneil/dariks_school_to_code_good/dev/logo.png)\n",
    "\n",
    "# Darik's School to Code Good\n",
    "### Writing clean, readable scientific Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a practical tour of **readability-first** scientific coding.\n",
    "\n",
    "## Learning goals\n",
    "By the end, you should be able to:\n",
    "- Choose names that communicate intent (and reduce bugs).\n",
    "- Refactor \"one big function\" into **small, testable pieces**.\n",
    "- Recognize and reduce **cyclomatic complexity**.\n",
    "- Write docstrings that make your future self (and labmates) happy.\n",
    "- Add lightweight input validation and helpful errors.\n",
    "- Practice the **test-driven development** loop on small scientific functions.\n",
    "\n",
    "> Teaching stance: prioritize code that is easy to read and hard to misuse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and a tiny simulated dataset\n",
    "We'll use a synthetic calcium-imaging-like dataset so the notebook runs anywhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reproducibility for demos\n",
    "rng = np.random.default_rng(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def simulate_calcium_data(\n",
    "    *,\n",
    "    num_neurons: int = 40,\n",
    "    duration_s: float = 60.0,\n",
    "    frame_rate_hz: float = 20.0,\n",
    "    baseline: float = 0.0,\n",
    "    noise_sd: float = 0.15,\n",
    "    event_rate_hz: float = 0.12,\n",
    "    tau_decay_s: float = 1.2,\n",
    "    rng: np.random.Generator | None = None,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Simulate calcium traces with sparse events convolved by an exponential kernel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_neurons:\n",
    "        Number of simulated neurons (columns in the returned fluorescence array).\n",
    "    duration_s:\n",
    "        Recording duration in seconds.\n",
    "    frame_rate_hz:\n",
    "        Sampling rate (frames per second).\n",
    "    baseline:\n",
    "        Additive baseline offset.\n",
    "    noise_sd:\n",
    "        Standard deviation of additive Gaussian noise.\n",
    "    event_rate_hz:\n",
    "        Poisson event rate per neuron (events / second).\n",
    "    tau_decay_s:\n",
    "        Exponential decay time constant.\n",
    "    rng:\n",
    "        Optional NumPy RNG for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    timestamps_s:\n",
    "        Array of shape (num_samples,) containing timestamps in seconds.\n",
    "    fluorescence:\n",
    "        Array of shape (num_samples, num_neurons).\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    if num_neurons <= 0:\n",
    "        raise ValueError(\"num_neurons must be positive\")\n",
    "    if duration_s <= 0 or frame_rate_hz <= 0:\n",
    "        raise ValueError(\"duration_s and frame_rate_hz must be positive\")\n",
    "    if tau_decay_s <= 0:\n",
    "        raise ValueError(\"tau_decay_s must be positive\")\n",
    "    if noise_sd < 0 or event_rate_hz < 0:\n",
    "        raise ValueError(\"noise_sd and event_rate_hz must be non-negative\")\n",
    "\n",
    "    num_samples = int(np.round(duration_s * frame_rate_hz))\n",
    "    timestamps_s = np.arange(num_samples) / frame_rate_hz\n",
    "\n",
    "    # Event train: Bernoulli approximation to Poisson per frame.\n",
    "    p_event = event_rate_hz / frame_rate_hz\n",
    "    events = rng.random((num_samples, num_neurons)) < p_event\n",
    "    events = events.astype(float)\n",
    "\n",
    "    # Exponential decay kernel (~10 taus long)\n",
    "    kernel_len = int(np.ceil(10 * tau_decay_s * frame_rate_hz))\n",
    "    t = np.arange(kernel_len) / frame_rate_hz\n",
    "    kernel = np.exp(-t / tau_decay_s)\n",
    "    kernel /= kernel.sum()\n",
    "\n",
    "    # Convolve each neuron (FFT conv for speed)\n",
    "    fluorescence = np.zeros_like(events, dtype=float)\n",
    "    for n in range(num_neurons):\n",
    "        fluorescence[:, n] = np.convolve(events[:, n], kernel, mode=\"same\")\n",
    "\n",
    "    fluorescence += baseline\n",
    "    fluorescence += rng.normal(0.0, noise_sd, size=fluorescence.shape)\n",
    "\n",
    "    # Add mild heterogeneity across neurons\n",
    "    fluorescence *= rng.lognormal(mean=0.0, sigma=0.25, size=(1, num_neurons))\n",
    "\n",
    "    return timestamps_s, fluorescence\n",
    "\n",
    "\n",
    "def plot_neuron(\n",
    "    timestamps_s: np.ndarray,\n",
    "    fluorescence: np.ndarray,\n",
    "    neuron_index: int,\n",
    "    *,\n",
    "    ax: plt.Axes | None = None,\n",
    "    title: str | None = None,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"Plot one neuron's fluorescence over time.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(10, 3))\n",
    "    ax.plot(timestamps_s, fluorescence[:, neuron_index])\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Fluorescence (a.u.)\")\n",
    "    ax.set_title(title or f\"Neuron {neuron_index}\")\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "timestamps_s, fluorescence = simulate_calcium_data(\n",
    "    num_neurons=60,\n",
    "    duration_s=90,\n",
    "    frame_rate_hz=20,\n",
    "    event_rate_hz=0.15,\n",
    "    tau_decay_s=1.0,\n",
    "    noise_sd=0.12,\n",
    "    rng=rng,\n",
    ")\n",
    "\n",
    "num_samples, num_neurons = fluorescence.shape\n",
    "print(f\"samples={num_samples:,}  neurons={num_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Quick look at a few neurons\n",
    "for n in [0, 1, 2]:\n",
    "    plot_neuron(timestamps_s, fluorescence, n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Core concepts\n",
    "\n",
    "We'll move from common pain points in analysis scripts to small, composable functions.\n",
    "\n",
    "## Roadmap\n",
    "1. Naming\n",
    "2. Modularity\n",
    "3. Cyclomatic complexity + least surprise + loose coupling\n",
    "4. Documentation (docstrings)\n",
    "5. Handling errors\n",
    "6. Test-driven development (TDD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The art of naming\n",
    "\n",
    "Names are the cheapest form of documentation. In practice, good names:\n",
    "- Tell you **what** something represents (and units, if relevant).\n",
    "- Tell you **why** it exists (purpose), not just its type.\n",
    "- Make incorrect usage feel awkward.\n",
    "\n",
    "We'll start with an intentionally unpleasant example.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fmp(x, y, t):\n",
    "    \"\"\"(Intentionally bad) Find neuron with most 'peaks' above a threshold.\n",
    "\n",
    "    Problems (on purpose):\n",
    "    - x, y, t don't communicate meaning\n",
    "    - threshold and minimum separation are conflated\n",
    "    - mixing lists + indexes makes off-by-one bugs easy\n",
    "    \"\"\"\n",
    "    s = len(x)\n",
    "    thr = t * np.std(y, axis=0)\n",
    "    a = []\n",
    "    for n in range(y.shape[1]):\n",
    "        i = 0\n",
    "        one = 0\n",
    "        pk = thr[n]\n",
    "        while i < s:\n",
    "            if y[i, n] > pk:\n",
    "                one += 1\n",
    "                i += t  # <- wait... why are we stepping by the threshold?\n",
    "            else:\n",
    "                i += 1\n",
    "        a.append(one)\n",
    "    return a.index(max(a))\n",
    "\n",
    "\n",
    "bad_answer = fmp(timestamps_s, fluorescence, 2)\n",
    "bad_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if this runs, it's hard to *trust*:\n",
    "\n",
    "- Is `t` a threshold? a stride? both?\n",
    "- Are events counted correctly?\n",
    "- What happens if we later change how thresholds are defined?\n",
    "\n",
    "Let's rewrite this so the call site explains itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_threshold_crossings(\n",
    "    trace: np.ndarray,\n",
    "    *,\n",
    "    threshold: float,\n",
    "    min_separation_samples: int,\n",
    ") -> int:\n",
    "    \"\"\"Count threshold crossings with a simple refractory period.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This is a deliberately simple event detector for teaching purposes.\n",
    "    For real event detection you'd likely use deconvolution or a validated method.\n",
    "    \"\"\"\n",
    "    if min_separation_samples < 1:\n",
    "        raise ValueError(\"min_separation_samples must be >= 1\")\n",
    "\n",
    "    count = 0\n",
    "    i = 0\n",
    "    n = trace.size\n",
    "    while i < n:\n",
    "        if trace[i] > threshold:\n",
    "            count += 1\n",
    "            i += min_separation_samples\n",
    "        else:\n",
    "            i += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def find_neuron_with_most_events(\n",
    "    fluorescence: np.ndarray,\n",
    "    *,\n",
    "    num_std_dev: float = 2.0,\n",
    "    min_separation_s: float = 0.25,\n",
    "    frame_rate_hz: float = 20.0,\n",
    ") -> int:\n",
    "    \"\"\"Return the neuron index with the most detected events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fluorescence:\n",
    "        Array of shape (num_samples, num_neurons).\n",
    "    num_std_dev:\n",
    "        Per-neuron threshold as `num_std_dev * std(trace)`.\n",
    "    min_separation_s:\n",
    "        Refractory period between events (seconds).\n",
    "    frame_rate_hz:\n",
    "        Sampling rate (Hz).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    neuron_index:\n",
    "        Integer index of the neuron with the most detected events.\n",
    "    \"\"\"\n",
    "    if fluorescence.ndim != 2:\n",
    "        raise ValueError(\"fluorescence must be 2D: (samples, neurons)\")\n",
    "    if num_std_dev <= 0:\n",
    "        raise ValueError(\"num_std_dev must be > 0\")\n",
    "    if min_separation_s <= 0 or frame_rate_hz <= 0:\n",
    "        raise ValueError(\"min_separation_s and frame_rate_hz must be > 0\")\n",
    "\n",
    "    min_sep = int(np.ceil(min_separation_s * frame_rate_hz))\n",
    "    thresholds = num_std_dev * np.std(fluorescence, axis=0)\n",
    "\n",
    "    counts = np.array(\n",
    "        [\n",
    "            count_threshold_crossings(\n",
    "                fluorescence[:, n],\n",
    "                threshold=thresholds[n],\n",
    "                min_separation_samples=min_sep,\n",
    "            )\n",
    "            for n in range(fluorescence.shape[1])\n",
    "        ]\n",
    "    )\n",
    "    return int(np.argmax(counts))\n",
    "\n",
    "\n",
    "good_answer = find_neuron_with_most_events(\n",
    "    fluorescence,\n",
    "    num_std_dev=2.0,\n",
    "    min_separation_s=0.25,\n",
    "    frame_rate_hz=20.0,\n",
    ")\n",
    "good_answer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The call site is now self-documenting:\n",
    "print(\"Bad answer:\", bad_answer)\n",
    "print(\"Good answer:\", good_answer)\n",
    "\n",
    "plot_neuron(timestamps_s, fluorescence, good_answer, title=\"Neuron with most detected events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modularity\n",
    "\n",
    "A modular function is:\n",
    "- **Small** enough to understand quickly,\n",
    "- **Pure** when possible (few side effects),\n",
    "- **Easy to test** in isolation,\n",
    "- Reusable in other analyses.\n",
    "\n",
    "A common failure mode is a single \"kitchen sink\" function that mixes:\n",
    "data access → preprocessing → detection → statistics → plotting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A monolithic version (example to refactor)\n",
    "\n",
    "Below is a plausible *anti-pattern*. It's here for reading, not for running.\n",
    "\n",
    "```python\n",
    "def calculate_iti_bad(timestamps_s, fluorescence, num_std_dev, min_separation):\n",
    "    # mixes event finding, neuron looping, and summary statistics\n",
    "    # easy to introduce bugs (e.g., neuron_index undefined)\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_event_indices(\n",
    "    trace: np.ndarray,\n",
    "    *,\n",
    "    threshold: float,\n",
    "    min_separation_samples: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return indices of detected events in a 1D trace.\"\"\"\n",
    "    indices = []\n",
    "    i = 0\n",
    "    n = trace.size\n",
    "    while i < n:\n",
    "        if trace[i] > threshold:\n",
    "            indices.append(i)\n",
    "            i += min_separation_samples\n",
    "        else:\n",
    "            i += 1\n",
    "    return np.asarray(indices, dtype=int)\n",
    "\n",
    "\n",
    "def event_times_from_indices(timestamps_s: np.ndarray, event_indices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Map event sample indices to event times (seconds).\"\"\"\n",
    "    return timestamps_s[event_indices]\n",
    "\n",
    "\n",
    "def inter_event_intervals_s(event_times_s: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute inter-event intervals (seconds).\"\"\"\n",
    "    if event_times_s.size < 2:\n",
    "        return np.array([], dtype=float)\n",
    "    return np.diff(event_times_s)\n",
    "\n",
    "\n",
    "def mean_interval(intervals_s: np.ndarray) -> float:\n",
    "    \"\"\"Mean of intervals; returns NaN if no intervals.\"\"\"\n",
    "    return float(np.mean(intervals_s)) if intervals_s.size else float(\"nan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mean_iti_for_neuron(\n",
    "    timestamps_s: np.ndarray,\n",
    "    fluorescence: np.ndarray,\n",
    "    neuron_index: int,\n",
    "    *,\n",
    "    num_std_dev: float,\n",
    "    min_separation_s: float,\n",
    "    frame_rate_hz: float,\n",
    ") -> float:\n",
    "    \"\"\"Mean inter-event interval (ITI) for one neuron.\"\"\"\n",
    "    if not (0 <= neuron_index < fluorescence.shape[1]):\n",
    "        raise IndexError(\"neuron_index out of range\")\n",
    "\n",
    "    min_sep = int(np.ceil(min_separation_s * frame_rate_hz))\n",
    "    threshold = float(num_std_dev * np.std(fluorescence[:, neuron_index]))\n",
    "\n",
    "    event_idx = find_event_indices(\n",
    "        fluorescence[:, neuron_index],\n",
    "        threshold=threshold,\n",
    "        min_separation_samples=min_sep,\n",
    "    )\n",
    "    event_t = event_times_from_indices(timestamps_s, event_idx)\n",
    "    itis = inter_event_intervals_s(event_t)\n",
    "    return mean_interval(itis)\n",
    "\n",
    "\n",
    "def neuron_with_smallest_mean_iti(\n",
    "    timestamps_s: np.ndarray,\n",
    "    fluorescence: np.ndarray,\n",
    "    *,\n",
    "    num_std_dev: float = 2.0,\n",
    "    min_separation_s: float = 0.25,\n",
    "    frame_rate_hz: float = 20.0,\n",
    ") -> int:\n",
    "    \"\"\"Return neuron index with smallest mean ITI (fastest event rate).\"\"\"\n",
    "    means = np.array(\n",
    "        [\n",
    "            mean_iti_for_neuron(\n",
    "                timestamps_s,\n",
    "                fluorescence,\n",
    "                n,\n",
    "                num_std_dev=num_std_dev,\n",
    "                min_separation_s=min_separation_s,\n",
    "                frame_rate_hz=frame_rate_hz,\n",
    "            )\n",
    "            for n in range(fluorescence.shape[1])\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n",
    "    # Treat NaNs (no events) as +inf so they don't win\n",
    "    means = np.where(np.isnan(means), np.inf, means)\n",
    "    return int(np.argmin(means))\n",
    "\n",
    "\n",
    "fastest_neuron = neuron_with_smallest_mean_iti(timestamps_s, fluorescence)\n",
    "fastest_neuron"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_neuron(timestamps_s, fluorescence, fastest_neuron, title=\"Neuron with smallest mean ITI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what modularity buys you:\n",
    "- Each helper is independently testable.\n",
    "- You can swap out `find_event_indices` without rewriting the statistics.\n",
    "- Bugs are localized to a small surface area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complexity, least surprise, and loose coupling\n",
    "\n",
    "### Cyclomatic complexity\n",
    "Cyclomatic complexity is (roughly) the number of independent paths through a function.\n",
    "High complexity often comes from many branches and deep nesting — which makes testing harder.\n",
    "\n",
    "### Principle of least surprise\n",
    "Try to make functions behave the way a reasonable reader expects:\n",
    "- clear parameter names\n",
    "- predictable return types\n",
    "- no hidden global state\n",
    "- no silent unit conversions\n",
    "\n",
    "### Loose coupling\n",
    "Prefer passing explicit inputs to a function over relying on global variables or I/O inside the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example: surprising behavior due to hidden global state\n",
    "GLOBAL_THRESHOLD_STD = 2.0  # <- don't do this in real analysis code\n",
    "\n",
    "\n",
    "def count_events_surprising(trace: np.ndarray) -> int:\n",
    "    \"\"\"Count events above GLOBAL_THRESHOLD_STD * std(trace). (Surprising!)\"\"\"\n",
    "    thr = GLOBAL_THRESHOLD_STD * np.std(trace)\n",
    "    return count_threshold_crossings(trace, threshold=thr, min_separation_samples=5)\n",
    "\n",
    "\n",
    "def count_events_explicit(trace: np.ndarray, *, num_std_dev: float, min_separation_samples: int) -> int:\n",
    "    \"\"\"Count events above num_std_dev * std(trace). (Explicit.)\"\"\"\n",
    "    thr = float(num_std_dev * np.std(trace))\n",
    "    return count_threshold_crossings(trace, threshold=thr, min_separation_samples=min_separation_samples)\n",
    "\n",
    "\n",
    "trace0 = fluorescence[:, 0]\n",
    "print(\"surprising:\", count_events_surprising(trace0))\n",
    "print(\"explicit:\", count_events_explicit(trace0, num_std_dev=2.0, min_separation_samples=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example: reduce nesting by using early returns (often lowers complexity)\n",
    "\n",
    "def classify_trace_quality_bad(trace: np.ndarray) -> str:\n",
    "    if trace.size > 0:\n",
    "        if np.isfinite(trace).all():\n",
    "            if np.std(trace) > 0:\n",
    "                if np.max(trace) < 10:\n",
    "                    return \"ok\"\n",
    "                else:\n",
    "                    return \"saturated\"\n",
    "            else:\n",
    "                return \"flat\"\n",
    "        else:\n",
    "            return \"nan_or_inf\"\n",
    "    else:\n",
    "        return \"empty\"\n",
    "\n",
    "\n",
    "def classify_trace_quality(trace: np.ndarray) -> str:\n",
    "    if trace.size == 0:\n",
    "        return \"empty\"\n",
    "    if not np.isfinite(trace).all():\n",
    "        return \"nan_or_inf\"\n",
    "    if np.std(trace) == 0:\n",
    "        return \"flat\"\n",
    "    if np.max(trace) >= 10:\n",
    "        return \"saturated\"\n",
    "    return \"ok\"\n",
    "\n",
    "\n",
    "print(classify_trace_quality_bad(trace0), classify_trace_quality(trace0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Documentation\n",
    "\n",
    "Docstrings are for **external communication**:\n",
    "- What the function does (one sentence).\n",
    "- Parameters (type, meaning, units).\n",
    "- Returns (shape/type, meaning).\n",
    "- Assumptions and edge cases.\n",
    "\n",
    "Inline comments are for **local clarification** of non-obvious steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def zscore_per_neuron(fluorescence: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Z-score each neuron independently.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fluorescence:\n",
    "        Array of shape (num_samples, num_neurons).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z:\n",
    "        Z-scored array of the same shape as `fluorescence`.\n",
    "        Each column has mean 0 and std 1 (unless std was 0, in which case the column is zeros).\n",
    "    \"\"\"\n",
    "    if fluorescence.ndim != 2:\n",
    "        raise ValueError(\"fluorescence must be 2D: (samples, neurons)\")\n",
    "\n",
    "    mu = np.mean(fluorescence, axis=0, keepdims=True)\n",
    "    sd = np.std(fluorescence, axis=0, keepdims=True)\n",
    "    sd_safe = np.where(sd == 0, 1.0, sd)\n",
    "    z = (fluorescence - mu) / sd_safe\n",
    "    # If sd was 0, define the result as 0 rather than NaN/Inf\n",
    "    z = np.where(sd == 0, 0.0, z)\n",
    "    return z\n",
    "\n",
    "\n",
    "z = zscore_per_neuron(fluorescence)\n",
    "z.shape, float(np.mean(z[:, 0])), float(np.std(z[:, 0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handle errors (and make misuse loud)\n",
    "\n",
    "Two pragmatic rules for analysis code:\n",
    "1. **Validate inputs at the boundary** (types/shapes/ranges).\n",
    "2. When something is wrong, fail **early** with an error message that tells you what to fix.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_fluorescence_matrix(fluorescence: np.ndarray) -> None:\n",
    "    \"\"\"Validate that fluorescence looks like (samples, neurons) numeric data.\"\"\"\n",
    "    if not isinstance(fluorescence, np.ndarray):\n",
    "        raise TypeError(\"fluorescence must be a NumPy array\")\n",
    "    if fluorescence.ndim != 2:\n",
    "        raise ValueError(f\"fluorescence must be 2D, got shape {fluorescence.shape}\")\n",
    "    if fluorescence.shape[0] < 2:\n",
    "        raise ValueError(\"need at least 2 samples\")\n",
    "    if fluorescence.shape[1] < 1:\n",
    "        raise ValueError(\"need at least 1 neuron\")\n",
    "    if not np.isfinite(fluorescence).all():\n",
    "        raise ValueError(\"fluorescence contains NaN or Inf\")\n",
    "\n",
    "\n",
    "# Demo: comment/uncomment to see a useful failure\n",
    "validate_fluorescence_matrix(fluorescence)\n",
    "print(\"validation ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test-driven development (TDD)\n",
    "\n",
    "A lightweight TDD loop:\n",
    "1. Write a test describing desired behavior (**fails**).\n",
    "2. Write the simplest code to make it pass.\n",
    "3. Refactor while keeping tests green.\n",
    "\n",
    "In notebooks you can start with `assert` tests. For real projects, move tests into `pytest`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Minimal \"notebook tests\" for a couple of helpers\n",
    "\n",
    "# count_threshold_crossings\n",
    "trace = np.array([0.0, 0.2, 1.5, 0.1, 2.0, 0.0])\n",
    "assert count_threshold_crossings(trace, threshold=1.0, min_separation_samples=1) == 2\n",
    "assert count_threshold_crossings(trace, threshold=1.0, min_separation_samples=2) == 2\n",
    "\n",
    "# inter_event_intervals_s\n",
    "assert np.allclose(inter_event_intervals_s(np.array([0.0, 0.5, 2.0])), np.array([0.5, 1.5]))\n",
    "assert inter_event_intervals_s(np.array([0.0])).size == 0\n",
    "\n",
    "print(\"basic tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What a pytest test might look like\n",
    "\n",
    "```python\n",
    "# test_events.py\n",
    "import numpy as np\n",
    "from your_module import count_threshold_crossings\n",
    "\n",
    "def test_count_threshold_crossings():\n",
    "    trace = np.array([0.0, 0.2, 1.5, 0.1, 2.0, 0.0])\n",
    "    assert count_threshold_crossings(trace, threshold=1.0, min_separation_samples=1) == 2\n",
    "```\n",
    "\n",
    "From the terminal:\n",
    "\n",
    "```bash\n",
    "pytest -q\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Modern tooling (fast, practical)\n",
    "\n",
    "You can write clean code **without** tools — but tools make it much easier to stay clean as a project grows.\n",
    "\n",
    "## Suggested minimal stack\n",
    "- **IDE**: PyCharm or VS Code (autocomplete, jump-to-definition, refactor tools).\n",
    "- **Formatter + linter**: `ruff` (format + lint).\n",
    "- **Tests**: `pytest`.\n",
    "- **Project/deps**: `uv` (fast environment + dependency management) *or* `pip + venv`.\n",
    "- **Automation**: `pre-commit` to run formatting/lint/tests before commits.\n",
    "\n",
    "## Typical commands (example)\n",
    "```bash\n",
    "# create env + install deps (one approach)\n",
    "uv venv\n",
    "uv pip install -r requirements.txt\n",
    "\n",
    "# format + lint\n",
    "ruff format .\n",
    "ruff check .\n",
    "\n",
    "# run tests\n",
    "pytest -q\n",
    "```\n",
    "\n",
    "## Notebook hygiene tips\n",
    "- Keep heavy logic in `.py` modules; notebooks should orchestrate + visualize.\n",
    "- Prefer small, reusable functions (then test them).\n",
    "- If you share notebooks, run them top-to-bottom before publishing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises (10–15 min)\n",
    "1. Modify `find_event_indices` to require a *rising-edge* crossing (to avoid counting sustained plateaus).\n",
    "2. Write tests that cover:\n",
    "   - no events,\n",
    "   - events exactly at threshold,\n",
    "   - extreme min_separation_samples.\n",
    "3. Refactor `find_neuron_with_most_events` so thresholds are computed by an injectable function\n",
    "   (e.g., `threshold_fn(trace) -> float`).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}