{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darik's School to Code Good\n",
    "## Best Practices for Writing Clean, Maintainable, Bug-Free Code\n",
    "\n",
    "Goal: make your code easier to **read, debug, reuse, and review**.\n",
    "\n",
    "We’ll cover:\n",
    "\n",
    "1. Variable naming\n",
    "2. Proper documentation\n",
    "3. Modularity & single responsibility\n",
    "4. Cyclomatic complexity\n",
    "5. Principle of least surprise\n",
    "6. Loose coupling\n",
    "7. Test-driven development (TDD)\n",
    "\n",
    "Throughout, think about your own analysis scripts and how you’d refactor them.\n"
   ],
   "id": "cb1385218e0cfbce"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports and helper for this notebook\n\n",
    "We'll use a couple of helpers for examples and tests.\n"
   ],
   "id": "a034e0a6d9700c9e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Callable\n\n",
    "import math\n",
    "import statistics as stats\n"
   ],
   "id": "9186aa9b809eedff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variable naming\n\n",
    "> *“Code is read much more often than it is written.”*\n\n",
    "**Bad patterns**\n",
    "- Single-letter or cryptic names (`a`, `x1`, `tmp2`)\n",
    "- Names that lie or are too generic (`data`, `results`, `val`)\n",
    "- Inconsistent conventions (`nTrials` vs `num_trials`)\n\n",
    "**Good patterns**\n",
    "- Names show *role* and *units* where relevant\n",
    "- Consistent style: `snake_case` for variables and functions in Python\n",
    "- Booleans that read as a statement: `is_valid`, `has_spikes`\n"
   ],
   "id": "c3c82054e4062b36"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ❌ Hard to read and understand\n",
    "def f(x, y):\n",
    "    # x is a list of times\n",
    "    # y is a list of vals\n",
    "    s = 0\n",
    "    n = 0\n",
    "    for i in range(len(x)):\n",
    "        if y[i] > 0:\n",
    "            s += y[i]\n",
    "            n += 1\n",
    "    return s / n\n"
   ],
   "id": "7a29324d2c022af9"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ✅ Clearer naming and intent\n",
    "def mean_positive(values: list[float]) -> float:\n",
    "    \"\"\"Compute the mean of strictly positive values in a list.\"\"\"\n",
    "    positive_values = [v for v in values if v > 0]\n",
    "    return stats.fmean(positive_values)\n"
   ],
   "id": "e568c0c0ef6ae543"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "Refactor this function with better variable names:\n\n",
    "```python\n",
    "def g(a, b):\n",
    "    r = []\n",
    "    for i in range(len(a)):\n",
    "        if a[i] > b:\n",
    "            r.append(a[i])\n",
    "    return r\n",
    "```\n\n",
    "- Rename the function to describe *what* it does.\n",
    "- Rename `a`, `b`, `r` to something meaningful.\n"
   ],
   "id": "c1072a99aa3d97d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Proper documentation\n\n",
    "We’ll focus on **docstrings**:\n\n",
    "- **What** the function does (one short sentence)\n",
    "- **Arguments** (types, meaning, units if relevant)\n",
    "- **Returns** (what and in what format)\n",
    "- Edge cases, assumptions, side effects\n\n",
    "Docstrings are for *external* communication.\n",
    "Inline comments are for *local* clarification of non-obvious steps.\n"
   ],
   "id": "a9a6851807b5c321"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_trace(trace, m=None, s=None):\n",
    "    if m is None:\n",
    "        m = sum(trace) / len(trace)\n",
    "    if s is None:\n",
    "        s = (sum((x - m)**2 for x in trace) / (len(trace) - 1))**0.5\n",
    "    return [(x - m)/s for x in trace]\n"
   ],
   "id": "91da1dc03961cbf4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def zscore_trace(\n",
    "    trace: list[float],\n",
    "    mean: float | None = None,\n",
    "    std: float | None = None,\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Z-score a 1D signal.\n\n",
    "    Parameters\n",
    "    ----------\n",
    "    trace : list of float\n",
    "        Signal values (e.g., fluorescence over time).\n",
    "    mean : float, optional\n",
    "        Pre-computed mean. If None, computed from `trace`.\n",
    "    std : float, optional\n",
    "        Pre-computed standard deviation. If None, computed from `trace`.\n\n",
    "    Returns\n",
    "    -------\n",
    "    list of float\n",
    "        Z-scored signal with zero mean and unit variance.\n",
    "    \"\"\"\n",
    "    if mean is None:\n",
    "        mean = stats.fmean(trace)\n",
    "    if std is None:\n",
    "        # Sample standard deviation\n",
    "        std = stats.stdev(trace)\n",
    "    return [(x - mean) / std for x in trace]\n"
   ],
   "id": "33eae13242375bd4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "- Add a docstring to `mean_positive` from above.\n",
    "- Include: what it does, expected input, what happens if there are no positives.\n"
   ],
   "id": "9b05a979f703ecf3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modularity & Single Responsibility\n\n",
    "A function should do **one thing** and do it well.\n\n",
    "Benefits:\n",
    "- Easier to test\n",
    "- Easier to reuse in a different context\n",
    "- Easier to change internal implementation without breaking callers\n"
   ],
   "id": "3ab920f6a8eefa2c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ❌ Everything in one blob\n",
    "def analyze_reaction_times(file_path: str, threshold: float = 1.0) -> float:\n",
    "    \"\"\"Return fraction of fast trials from a CSV file of reaction times.\"\"\"\n",
    "    # load CSV\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "    rts = []\n",
    "    for line in lines[1:]:  # skip header\n",
    "        rt = float(line.strip().split(\",\")[1])\n",
    "        rts.append(rt)\n",
    "    # clean\n",
    "    rts = [rt for rt in rts if rt > 0]\n",
    "    # compute metric\n",
    "    fast = [rt for rt in rts if rt < threshold]\n",
    "    return len(fast) / len(rts)\n"
   ],
   "id": "38cd131bfecf9fdc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ✅ Decomposed into focused pieces\n",
    "def load_reaction_times(file_path: str) -> list[float]:\n",
    "    \"\"\"Load reaction times from a CSV with header, reaction time in column 2.\"\"\"\n",
    "    rts: list[float] = []\n",
    "    with open(file_path) as f:\n",
    "        next(f)  # skip header\n",
    "        for line in f:\n",
    "            _, rt_str = line.strip().split(\",\")\n",
    "            rts.append(float(rt_str))\n",
    "    return rts\n\n\n",
    "def filter_valid_reaction_times(reaction_times: list[float]) -> list[float]:\n",
    "    \"\"\"Filter out invalid reaction times (<= 0).\"\"\"\n",
    "    return [rt for rt in reaction_times if rt > 0]\n\n\n",
    "def fraction_fast_trials(\n",
    "    reaction_times: list[float],\n",
    "    threshold: float = 1.0,\n",
    ") -> float:\n",
    "    \"\"\"Compute fraction of trials with reaction time below threshold (s).\"\"\"\n",
    "    valid_rts = filter_valid_reaction_times(reaction_times)\n",
    "    fast_trials = [rt for rt in valid_rts if rt < threshold]\n",
    "    return len(fast_trials) / len(valid_rts)\n"
   ],
   "id": "4b846610fd8ad8e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "- Imagine you have a function that:\n",
    "  1. Loads imaging data\n",
    "  2. Motion-corrects it\n",
    "  3. Extracts ΔF/F\n",
    "  4. Plots the result\n\n",
    "Sketch how you would split that into 3–5 smaller functions with single responsibilities.\n",
    "(No need to implement fully here; just function names + docstrings.)\n"
   ],
   "id": "ed109fdbe1e94432"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cyclomatic complexity\n\n",
    "Cyclomatic complexity ~ **number of independent paths** through your code.\n\n",
    "High complexity:\n",
    "- Many `if`/`elif` branches\n",
    "- Deeply nested loops / conditionals\n",
    "- Harder to test and reason about\n\n",
    "Rule of thumb: keep functions simple enough that you can hold the logic in your head.\n"
   ],
   "id": "be6e8a3888cdf1b5"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ❌ Dense branching; hard to test exhaustively\n",
    "def classify_trial(rt: float, accuracy: bool, difficulty: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify a single trial as 'good', 'ok', or 'bad'.\n",
    "    \"\"\"\n",
    "    if difficulty == \"easy\":\n",
    "        if accuracy and rt < 0.7:\n",
    "            return \"good\"\n",
    "        elif accuracy and rt < 1.0:\n",
    "            return \"ok\"\n",
    "        else:\n",
    "            return \"bad\"\n",
    "    elif difficulty == \"hard\":\n",
    "        if accuracy and rt < 1.2:\n",
    "            return \"good\"\n",
    "        elif accuracy and rt < 1.6:\n",
    "            return \"ok\"\n",
    "        else:\n",
    "            return \"bad\"\n",
    "    else:\n",
    "        if accuracy and rt < 1.0:\n",
    "            return \"good\"\n",
    "        elif accuracy and rt < 1.4:\n",
    "            return \"ok\"\n",
    "        else:\n",
    "            return \"bad\"\n"
   ],
   "id": "8b863efcd443f3d3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def difficulty_thresholds(difficulty: str) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return (good_threshold, ok_threshold) in seconds for each difficulty.\n",
    "    \"\"\"\n",
    "    if difficulty == \"easy\":\n",
    "        return 0.7, 1.0\n",
    "    if difficulty == \"hard\":\n",
    "        return 1.2, 1.6\n",
    "    # default\n",
    "    return 1.0, 1.4\n\n\n",
    "def classify_trial(rt: float, accuracy: bool, difficulty: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify a trial as 'good', 'ok', or 'bad'.\n",
    "    \"\"\"\n",
    "    good_threshold, ok_threshold = difficulty_thresholds(difficulty)\n\n",
    "    if not accuracy:\n",
    "        return \"bad\"\n",
    "    if rt < good_threshold:\n",
    "        return \"good\"\n",
    "    if rt < ok_threshold:\n",
    "        return \"ok\"\n",
    "    return \"bad\"\n"
   ],
   "id": "85e88bbee2de2e6f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "- Where did we reduce cyclomatic complexity in `classify_trial`?\n",
    "- How would you further simplify if the classification rules changed often?\n"
   ],
   "id": "fda4660f52da46ce"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Principle of Least Surprise\n\n",
    "Code should behave in a way that is **unsurprising** to someone who knows the language and your domain.\n\n",
    "Surprising behavior:\n",
    "- Functions that mutate arguments when callers expect a copy\n",
    "- Functions with hidden global state / side effects\n",
    "- Functions that return different *types* depending on inputs\n"
   ],
   "id": "cdf6fa3cccc7f2d1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ❌ Surprising: mutates default list; default argument is shared between calls\n",
    "def collect_values(x, values=[]):\n",
    "    values.append(x)\n",
    "    return values\n\n",
    "print(collect_values(1))\n",
    "print(collect_values(2))  # surprise: previous call's data is still there\n"
   ],
   "id": "d23fdb44ede5815d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ✅ No shared mutable default\n",
    "def collect_values(x, values=None):\n",
    "    \"\"\"\n",
    "    Append `x` to an existing list or create a new one.\n",
    "    \"\"\"\n",
    "    if values is None:\n",
    "        values = []\n",
    "    values.append(x)\n",
    "    return values\n\n",
    "print(collect_values(1))\n",
    "print(collect_values(2))\n"
   ],
   "id": "b7b9c3d8c50ee590"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "- Think of a function in your own code that might surprise a new lab member.\n",
    "  - Does it mutate inputs?\n",
    "  - Does it read from / write to global variables?\n",
    "- Write down one change you could make to reduce surprise.\n"
   ],
   "id": "39bdd56d2c13dd97"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loose coupling\n\n",
    "**Coupling** = how strongly different parts of your system depend on each other.\n\n",
    "We want:\n",
    "- Modules that know as little as possible about each other's internals\n",
    "- Clear *interfaces* (function signatures, return types) instead of hidden shared state\n",
    "- Easier replacement / reuse (e.g., swapping a file loader for a database loader)\n"
   ],
   "id": "c5aed726dc4505c2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ❌ Analysis function knows too much about how data is stored on disk\n",
    "def compute_mean_fluorescence(mouse_id: str) -> float:\n",
    "    file_path = f\"./data/{mouse_id}_day1_fov1.csv\"\n",
    "    with open(file_path) as f:\n",
    "        next(f)\n",
    "        values = [float(line.strip().split(\",\")[0]) for line in f]\n",
    "    return stats.fmean(values)\n"
   ],
   "id": "6f5ade80e53b9a29"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ✅ Analysis depends on an interface, not on disk layout\n",
    "def compute_mean_signal(\n",
    "    loader: Callable[[str], list[float]],\n",
    "    session_id: str,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute mean signal using a generic loader.\n\n",
    "    The loader is any function that takes a session_id and returns a list of floats.\n",
    "    \"\"\"\n",
    "    signal = loader(session_id)\n",
    "    return stats.fmean(signal)\n\n\n",
    "def csv_signal_loader(session_id: str) -> list[float]:\n",
    "    file_path = f\"./data/{session_id}.csv\"\n",
    "    with open(file_path) as f:\n",
    "        next(f)\n",
    "        return [float(line.strip().split(\",\")[0]) for line in f]\n\n\n",
    "# Later you can swap to another loader without changing compute_mean_signal:\n",
    "# def hdf5_signal_loader(session_id: str) -> list[float]:\n",
    "#     ...\n"
   ],
   "id": "71283193991f140e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "- Identify a function in your work that:\n",
    "  - Both **loads** data and **analyzes** it.\n",
    "- Write a new function signature that would separate loading from analysis.\n\n",
    "Example pattern:\n\n",
    "```python\n",
    "def analyze_trials(load_trials: Callable[[str], list[Trial]], experiment_id: str) -> AnalysisResult:\n",
    "    ...\n",
    "```\n"
   ],
   "id": "29026294b37250dc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test-Driven Development (TDD)\n\n",
    "TDD cycle:\n\n",
    "1. **Write a test** that describes desired behavior (it should fail).\n",
    "2. **Write the minimal code** to make the test pass.\n",
    "3. **Refactor** while keeping tests green.\n\n",
    "For teaching, we’ll use the built-in `assert` statements, but in practice you’d use `pytest`.\n"
   ],
   "id": "4f7c80f7461940a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Write tests first\n\n",
    "We want a function `percent_change(old, new)` that:\n\n",
    "- Returns percent change as a float (e.g., from 10 to 15 → 50.0)\n",
    "- Raises `ValueError` if `old == 0` to avoid division by zero\n"
   ],
   "id": "e705a95a9e743f5b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_percent_change_basic():\n",
    "    assert percent_change(10, 15) == 50.0\n",
    "    assert percent_change(20, 10) == -50.0\n",
    "    assert percent_change(5, 5) == 0.0\n\n\n",
    "def test_percent_change_zero_old():\n",
    "    try:\n",
    "        percent_change(0, 10)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"Expected ValueError when old == 0\")\n\n",
    "# Run tests (they will fail because percent_change is not defined yet)\n",
    "try:\n",
    "    test_percent_change_basic()\n",
    "    test_percent_change_zero_old()\n",
    "    print(\"All tests passed (unexpected)\")\n",
    "except NameError as e:\n",
    "    print(\"As expected, tests fail before implementation:\", e)\n"
   ],
   "id": "4d596724ba76f6e4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def percent_change(old: float, new: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute percent change from `old` to `new`.\n\n",
    "    Example: old=10, new=15 -> 50.0\n",
    "    \"\"\"\n",
    "    if old == 0:\n",
    "        raise ValueError(\"old must be non-zero to compute percent change\")\n",
    "    return (new - old) / old * 100.0\n"
   ],
   "id": "775e08a278136c50"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_percent_change_basic()\n",
    "test_percent_change_zero_old()\n",
    "print(\"All tests passed ✅\")\n"
   ],
   "id": "b999f20f40e951a8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n\n",
    "- Pick a small function from earlier in this notebook (e.g., `mean_positive`).\n",
    "- Write 2–3 tests for it:\n",
    "  - A normal case\n",
    "  - An edge case\n",
    "  - A failure case (if appropriate)\n",
    "- Only then modify the function to satisfy those tests.\n"
   ],
   "id": "5c3c3411e72fe7ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary checklist\n\n",
    "When you write or review code, ask:\n\n",
    "1. **Names**\n",
    "   - Are function and variable names descriptive?\n",
    "   - Do booleans read like true/false statements?\n\n",
    "2. **Documentation**\n",
    "   - Does each function have a clear one-line summary?\n",
    "   - Are arguments and return values documented (including units)?\n\n",
    "3. **Modularity**\n",
    "   - Does each function do one job?\n",
    "   - Could you test it in isolation?\n\n",
    "4. **Cyclomatic complexity**\n",
    "   - Are there many deeply nested `if`/`for` blocks?\n",
    "   - Can you extract helpers to simplify?\n\n",
    "5. **Principle of least surprise**\n",
    "   - Would behavior surprise a new lab member?\n",
    "   - Any hidden side effects or type changes?\n\n",
    "6. **Loose coupling**\n",
    "   - Does analysis code depend directly on file paths / globals?\n",
    "   - Can you introduce clear interfaces (functions, classes) instead?\n\n",
    "7. **Tests / TDD**\n",
    "   - Is there at least one test for non-trivial functions?\n",
    "   - Could you write the next function by starting from tests?\n\n",
    "---\n\n",
    "### Optional extension\n\n",
    "In a real project, you would also add:\n\n",
    "- **Linting** (e.g., `ruff`, `flake8`) and **formatting** (`black`)\n",
    "- **Type checking** with `mypy` or `pyright`\n",
    "- A `tests/` directory with `pytest` tests\n",
    "- A `README` describing how to run the code\n\n",
    "Use this notebook as a starting point and adapt the examples to your own lab codebase.\n"
   ],
   "id": "a4bb44b645f7161b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
